{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63a1283",
   "metadata": {},
   "source": [
    "# LeNet\n",
    "\n",
    "On MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5daf3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from src.models import LeNet, MiniLeNet\n",
    "import src.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5845cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Device\n",
    "use_cuda = True and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else 'cpu')\n",
    "\n",
    "# Load models\n",
    "model_init = torch.load('../saves/LeNet_initial_model.ptmodel', weights_only=False)\n",
    "model_pruned_retrained = torch.load('../saves/LeNet_model_after_retraining.ptmodel', weights_only=False)\n",
    "model_weight_shared = torch.load('../saves/LeNet_model_after_weight_sharing.ptmodel', weights_only=False)\n",
    "model_decoded = torch.load('../saves/LeNet_model_after_decoding.ptmodel', weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1255d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (fc1): MaskedLinear(in_features=784, out_features=300, bias=True)\n",
       "  (fc2): MaskedLinear(in_features=300, out_features=100, bias=True)\n",
       "  (fc3): MaskedLinear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570d6d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial LeNet's parameter number : 532810\n",
      "Storage space needed by initial LeNet : 2.04 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial LeNet's parameter number :\",sum(p.numel() for p in model_init.parameters()))\n",
    "\n",
    "path = os.path.expanduser('../saves/LeNet_initial_model.ptmodel')\n",
    "size_mb_init = os.path.getsize(path) / 1024**2\n",
    "print(f\"Storage space needed by initial LeNet : {size_mb_init:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "337e57a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer                                Params     Memory (MB)\n",
      "------------------------------------------------------------\n",
      "fc1.weight                          235,200            0.90\n",
      "fc1.mask                            235,200            0.90\n",
      "fc1.bias                                300            0.00\n",
      "fc2.weight                           30,000            0.11\n",
      "fc2.mask                             30,000            0.11\n",
      "fc2.bias                                100            0.00\n",
      "fc3.weight                            1,000            0.00\n",
      "fc3.mask                              1,000            0.00\n",
      "fc3.bias                                 10            0.00\n",
      "------------------------------------------------------------\n",
      "TOTAL                                                  2.03 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Layer':30} {'Params':>12} {'Memory (MB)':>15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "total_mem = 0\n",
    "\n",
    "for name, param in model_init.named_parameters():\n",
    "    num_params = param.numel()\n",
    "    mem_mb = num_params * param.element_size() / 1024**2\n",
    "    total_mem += mem_mb\n",
    "    print(f\"{name:30} {num_params:12,d} {mem_mb:15.2f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'TOTAL':30} {'':12} {total_mem:15.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b30dae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage space needed by encoded LeNet : 25.55 kB (0.02 MB)\n"
     ]
    }
   ],
   "source": [
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dir_names, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # Vérifie si le fichier existe (évite les liens brisés)\n",
    "            if os.path.exists(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "path = os.path.expanduser('../LeNet_encodings/')\n",
    "size_bytes = get_folder_size(path)\n",
    "size_kb = size_bytes / 1024\n",
    "size_mb = size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"Storage space needed by encoded LeNet : {size_kb:.2f} kB ({size_mb:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c328da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet compression rate with Pruning, Quantization and Huffman coding : 81.7x\n"
     ]
    }
   ],
   "source": [
    "print(f\"LeNet compression rate with Pruning, Quantization and Huffman coding : {size_mb_init/size_mb:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ac69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniLeNet's parameter number : 6442\n",
      "Storage space needed by mini LeNet : 29.06 kB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1da18fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = {'LeNet' : (0.1307,)}\n",
    "std  = {'LeNet' : (0.3081,)}\n",
    "\n",
    "def train(model, epochs):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean['LeNet'], std['LeNet'])\n",
    "                    ])),\n",
    "        batch_size=100, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0001)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # zero-out all the gradients corresponding to the pruned connections\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'mask' in name:\n",
    "                    continue\n",
    "                tensor = p.data.cpu().numpy()\n",
    "                grad_tensor = p.grad.data.cpu().numpy()\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                done = batch_idx * len(data)\n",
    "                percentage = 100. * batch_idx / len(train_loader)\n",
    "                pbar.set_description(f'Train Epoch: {epoch} [{done:5}/{len(train_loader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ba7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, use_cuda=True):\n",
    "    kwargs = {'num_workers': 5, 'pin_memory': True} if use_cuda else {}\n",
    "    device = torch.device(\"cuda\" if use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean['LeNet'], std['LeNet'])\n",
    "                    ])),\n",
    "        batch_size=1000, shuffle=False, **kwargs)\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a81eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniLeNet's parameter number : 6442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [59000/60000 ( 98%)]  Loss: 0.246136: 100%|██████████| 600/600 [00:09<00:00, 63.08it/s]\n",
      "Train Epoch: 1 [59000/60000 ( 98%)]  Loss: 0.319840: 100%|██████████| 600/600 [00:09<00:00, 64.02it/s]\n",
      "Train Epoch: 2 [59000/60000 ( 98%)]  Loss: 0.217113: 100%|██████████| 600/600 [00:12<00:00, 47.43it/s]\n",
      "Train Epoch: 3 [59000/60000 ( 98%)]  Loss: 0.083715: 100%|██████████| 600/600 [00:11<00:00, 51.95it/s]\n",
      "Train Epoch: 4 [59000/60000 ( 98%)]  Loss: 0.349848: 100%|██████████| 600/600 [00:09<00:00, 64.90it/s]\n",
      "Train Epoch: 5 [59000/60000 ( 98%)]  Loss: 0.343872: 100%|██████████| 600/600 [00:09<00:00, 65.54it/s]\n",
      "Train Epoch: 6 [59000/60000 ( 98%)]  Loss: 0.172695: 100%|██████████| 600/600 [00:10<00:00, 58.80it/s]\n",
      "Train Epoch: 7 [59000/60000 ( 98%)]  Loss: 0.172233: 100%|██████████| 600/600 [00:09<00:00, 61.05it/s]\n",
      "Train Epoch: 8 [59000/60000 ( 98%)]  Loss: 0.272068: 100%|██████████| 600/600 [00:09<00:00, 63.66it/s]\n",
      "Train Epoch: 9 [59000/60000 ( 98%)]  Loss: 0.407102: 100%|██████████| 600/600 [00:09<00:00, 63.14it/s]\n",
      "Train Epoch: 10 [59000/60000 ( 98%)]  Loss: 0.243274: 100%|██████████| 600/600 [00:09<00:00, 64.34it/s]\n",
      "Train Epoch: 11 [59000/60000 ( 98%)]  Loss: 0.309972: 100%|██████████| 600/600 [00:09<00:00, 63.76it/s]\n",
      "Train Epoch: 12 [59000/60000 ( 98%)]  Loss: 0.379756: 100%|██████████| 600/600 [00:09<00:00, 64.70it/s]\n",
      "Train Epoch: 13 [59000/60000 ( 98%)]  Loss: 0.176961: 100%|██████████| 600/600 [00:09<00:00, 64.11it/s]\n",
      "Train Epoch: 14 [59000/60000 ( 98%)]  Loss: 0.354284: 100%|██████████| 600/600 [00:09<00:00, 64.07it/s]\n",
      "Train Epoch: 15 [59000/60000 ( 98%)]  Loss: 0.295121: 100%|██████████| 600/600 [00:09<00:00, 64.65it/s]\n",
      "Train Epoch: 16 [59000/60000 ( 98%)]  Loss: 0.231262: 100%|██████████| 600/600 [00:09<00:00, 64.39it/s]\n",
      "Train Epoch: 17 [59000/60000 ( 98%)]  Loss: 0.093342: 100%|██████████| 600/600 [00:09<00:00, 63.76it/s]\n",
      "Train Epoch: 18 [59000/60000 ( 98%)]  Loss: 0.195260: 100%|██████████| 600/600 [00:09<00:00, 64.24it/s]\n",
      "Train Epoch: 19 [59000/60000 ( 98%)]  Loss: 0.398833: 100%|██████████| 600/600 [00:09<00:00, 63.97it/s]\n",
      "Train Epoch: 20 [59000/60000 ( 98%)]  Loss: 0.196554: 100%|██████████| 600/600 [00:09<00:00, 63.68it/s]\n",
      "Train Epoch: 21 [59000/60000 ( 98%)]  Loss: 0.205512: 100%|██████████| 600/600 [00:09<00:00, 64.00it/s]\n",
      "Train Epoch: 22 [59000/60000 ( 98%)]  Loss: 0.209906: 100%|██████████| 600/600 [00:09<00:00, 64.29it/s]\n",
      "Train Epoch: 23 [59000/60000 ( 98%)]  Loss: 0.154247: 100%|██████████| 600/600 [00:09<00:00, 63.92it/s]\n",
      "Train Epoch: 24 [59000/60000 ( 98%)]  Loss: 0.294866: 100%|██████████| 600/600 [00:09<00:00, 64.49it/s]\n",
      "Train Epoch: 25 [59000/60000 ( 98%)]  Loss: 0.257671: 100%|██████████| 600/600 [00:09<00:00, 64.02it/s]\n",
      "Train Epoch: 26 [59000/60000 ( 98%)]  Loss: 0.155484: 100%|██████████| 600/600 [00:09<00:00, 64.21it/s]\n",
      "Train Epoch: 27 [59000/60000 ( 98%)]  Loss: 0.288884: 100%|██████████| 600/600 [00:09<00:00, 64.20it/s]\n",
      "Train Epoch: 28 [59000/60000 ( 98%)]  Loss: 0.456020: 100%|██████████| 600/600 [00:09<00:00, 63.94it/s]\n",
      "Train Epoch: 29 [59000/60000 ( 98%)]  Loss: 0.305641: 100%|██████████| 600/600 [00:09<00:00, 64.42it/s]\n",
      "Train Epoch: 30 [59000/60000 ( 98%)]  Loss: 0.172128: 100%|██████████| 600/600 [00:09<00:00, 60.24it/s]\n",
      "Train Epoch: 31 [59000/60000 ( 98%)]  Loss: 0.278392: 100%|██████████| 600/600 [00:10<00:00, 58.46it/s]\n",
      "Train Epoch: 32 [59000/60000 ( 98%)]  Loss: 0.194746: 100%|██████████| 600/600 [00:09<00:00, 61.19it/s]\n",
      "Train Epoch: 33 [59000/60000 ( 98%)]  Loss: 0.336533: 100%|██████████| 600/600 [00:09<00:00, 61.96it/s]\n",
      "Train Epoch: 34 [59000/60000 ( 98%)]  Loss: 0.277166: 100%|██████████| 600/600 [00:09<00:00, 62.21it/s]\n",
      "Train Epoch: 35 [59000/60000 ( 98%)]  Loss: 0.272341: 100%|██████████| 600/600 [00:09<00:00, 62.38it/s]\n",
      "Train Epoch: 36 [59000/60000 ( 98%)]  Loss: 0.203006: 100%|██████████| 600/600 [00:09<00:00, 64.49it/s]\n",
      "Train Epoch: 37 [59000/60000 ( 98%)]  Loss: 0.482454: 100%|██████████| 600/600 [00:09<00:00, 60.95it/s]\n",
      "Train Epoch: 38 [59000/60000 ( 98%)]  Loss: 0.183033: 100%|██████████| 600/600 [00:09<00:00, 60.01it/s]\n",
      "Train Epoch: 39 [59000/60000 ( 98%)]  Loss: 0.379407: 100%|██████████| 600/600 [00:09<00:00, 61.99it/s]\n",
      "Train Epoch: 40 [59000/60000 ( 98%)]  Loss: 0.201330: 100%|██████████| 600/600 [00:09<00:00, 62.01it/s]\n",
      "Train Epoch: 41 [59000/60000 ( 98%)]  Loss: 0.251239: 100%|██████████| 600/600 [00:09<00:00, 61.04it/s]\n",
      "Train Epoch: 42 [59000/60000 ( 98%)]  Loss: 0.172583: 100%|██████████| 600/600 [00:09<00:00, 63.18it/s]\n",
      "Train Epoch: 43 [59000/60000 ( 98%)]  Loss: 0.292335: 100%|██████████| 600/600 [00:09<00:00, 60.71it/s]\n",
      "Train Epoch: 44 [59000/60000 ( 98%)]  Loss: 0.267030: 100%|██████████| 600/600 [00:10<00:00, 56.85it/s]\n",
      "Train Epoch: 45 [59000/60000 ( 98%)]  Loss: 0.252715: 100%|██████████| 600/600 [00:10<00:00, 59.56it/s]\n",
      "Train Epoch: 46 [59000/60000 ( 98%)]  Loss: 0.160447: 100%|██████████| 600/600 [00:09<00:00, 62.35it/s]\n",
      "Train Epoch: 47 [59000/60000 ( 98%)]  Loss: 0.159663: 100%|██████████| 600/600 [00:09<00:00, 65.86it/s]\n",
      "Train Epoch: 48 [59000/60000 ( 98%)]  Loss: 0.274014: 100%|██████████| 600/600 [00:09<00:00, 65.59it/s]\n",
      "Train Epoch: 49 [59000/60000 ( 98%)]  Loss: 0.380137: 100%|██████████| 600/600 [00:09<00:00, 65.35it/s]\n",
      "Train Epoch: 50 [59000/60000 ( 98%)]  Loss: 0.314193: 100%|██████████| 600/600 [00:09<00:00, 64.97it/s]\n",
      "Train Epoch: 51 [59000/60000 ( 98%)]  Loss: 0.360940: 100%|██████████| 600/600 [00:09<00:00, 65.37it/s]\n",
      "Train Epoch: 52 [59000/60000 ( 98%)]  Loss: 0.141939: 100%|██████████| 600/600 [00:09<00:00, 65.14it/s]\n",
      "Train Epoch: 53 [59000/60000 ( 98%)]  Loss: 0.265734: 100%|██████████| 600/600 [00:09<00:00, 63.13it/s]\n",
      "Train Epoch: 54 [59000/60000 ( 98%)]  Loss: 0.183934: 100%|██████████| 600/600 [00:10<00:00, 59.05it/s]\n",
      "Train Epoch: 55 [59000/60000 ( 98%)]  Loss: 0.335085: 100%|██████████| 600/600 [00:09<00:00, 61.50it/s]\n",
      "Train Epoch: 56 [59000/60000 ( 98%)]  Loss: 0.310529: 100%|██████████| 600/600 [00:09<00:00, 61.78it/s]\n",
      "Train Epoch: 57 [59000/60000 ( 98%)]  Loss: 0.144373: 100%|██████████| 600/600 [00:10<00:00, 59.74it/s]\n",
      "Train Epoch: 58 [59000/60000 ( 98%)]  Loss: 0.171577: 100%|██████████| 600/600 [00:09<00:00, 61.07it/s]\n",
      "Train Epoch: 59 [59000/60000 ( 98%)]  Loss: 0.260436: 100%|██████████| 600/600 [00:09<00:00, 61.03it/s]\n",
      "Train Epoch: 60 [59000/60000 ( 98%)]  Loss: 0.364941: 100%|██████████| 600/600 [00:09<00:00, 62.59it/s]\n",
      "Train Epoch: 61 [59000/60000 ( 98%)]  Loss: 0.291802: 100%|██████████| 600/600 [00:10<00:00, 59.70it/s]\n",
      "Train Epoch: 62 [59000/60000 ( 98%)]  Loss: 0.187834: 100%|██████████| 600/600 [00:10<00:00, 57.76it/s]\n",
      "Train Epoch: 63 [59000/60000 ( 98%)]  Loss: 0.135780: 100%|██████████| 600/600 [00:10<00:00, 59.93it/s]\n",
      "Train Epoch: 64 [59000/60000 ( 98%)]  Loss: 0.247857: 100%|██████████| 600/600 [00:10<00:00, 58.46it/s]\n",
      "Train Epoch: 65 [59000/60000 ( 98%)]  Loss: 0.375926: 100%|██████████| 600/600 [00:10<00:00, 59.05it/s]\n",
      "Train Epoch: 66 [59000/60000 ( 98%)]  Loss: 0.165148: 100%|██████████| 600/600 [00:09<00:00, 61.31it/s]\n",
      "Train Epoch: 67 [59000/60000 ( 98%)]  Loss: 0.448144: 100%|██████████| 600/600 [00:09<00:00, 62.56it/s]\n",
      "Train Epoch: 68 [59000/60000 ( 98%)]  Loss: 0.335307: 100%|██████████| 600/600 [00:09<00:00, 65.03it/s]\n",
      "Train Epoch: 69 [59000/60000 ( 98%)]  Loss: 0.179471: 100%|██████████| 600/600 [00:09<00:00, 63.61it/s]\n",
      "Train Epoch: 70 [59000/60000 ( 98%)]  Loss: 0.260848: 100%|██████████| 600/600 [00:09<00:00, 63.62it/s]\n",
      "Train Epoch: 71 [59000/60000 ( 98%)]  Loss: 0.271123: 100%|██████████| 600/600 [00:09<00:00, 64.10it/s]\n",
      "Train Epoch: 72 [59000/60000 ( 98%)]  Loss: 0.191864: 100%|██████████| 600/600 [00:10<00:00, 59.65it/s]\n",
      "Train Epoch: 73 [59000/60000 ( 98%)]  Loss: 0.293396: 100%|██████████| 600/600 [00:09<00:00, 64.36it/s]\n",
      "Train Epoch: 74 [59000/60000 ( 98%)]  Loss: 0.255510: 100%|██████████| 600/600 [00:09<00:00, 62.70it/s]\n",
      "Train Epoch: 75 [59000/60000 ( 98%)]  Loss: 0.349198: 100%|██████████| 600/600 [00:09<00:00, 63.00it/s]\n",
      "Train Epoch: 76 [59000/60000 ( 98%)]  Loss: 0.344626: 100%|██████████| 600/600 [00:09<00:00, 65.08it/s]\n",
      "Train Epoch: 77 [59000/60000 ( 98%)]  Loss: 0.419136: 100%|██████████| 600/600 [00:09<00:00, 65.16it/s]\n",
      "Train Epoch: 78 [59000/60000 ( 98%)]  Loss: 0.351919: 100%|██████████| 600/600 [00:09<00:00, 64.94it/s]\n",
      "Train Epoch: 79 [59000/60000 ( 98%)]  Loss: 0.216958: 100%|██████████| 600/600 [00:09<00:00, 65.29it/s]\n",
      "Train Epoch: 80 [59000/60000 ( 98%)]  Loss: 0.211308: 100%|██████████| 600/600 [00:09<00:00, 65.34it/s]\n",
      "Train Epoch: 81 [59000/60000 ( 98%)]  Loss: 0.177233: 100%|██████████| 600/600 [00:09<00:00, 65.56it/s]\n",
      "Train Epoch: 82 [59000/60000 ( 98%)]  Loss: 0.310574: 100%|██████████| 600/600 [00:09<00:00, 65.39it/s]\n",
      "Train Epoch: 83 [59000/60000 ( 98%)]  Loss: 0.389414: 100%|██████████| 600/600 [00:09<00:00, 62.02it/s]\n",
      "Train Epoch: 84 [59000/60000 ( 98%)]  Loss: 0.203723: 100%|██████████| 600/600 [00:10<00:00, 59.13it/s]\n",
      "Train Epoch: 85 [59000/60000 ( 98%)]  Loss: 0.212449: 100%|██████████| 600/600 [00:11<00:00, 53.57it/s]\n",
      "Train Epoch: 86 [59000/60000 ( 98%)]  Loss: 0.312337: 100%|██████████| 600/600 [00:10<00:00, 57.86it/s]\n",
      "Train Epoch: 87 [59000/60000 ( 98%)]  Loss: 0.313859: 100%|██████████| 600/600 [00:10<00:00, 59.06it/s]\n",
      "Train Epoch: 88 [59000/60000 ( 98%)]  Loss: 0.201832: 100%|██████████| 600/600 [00:09<00:00, 62.77it/s]\n",
      "Train Epoch: 89 [59000/60000 ( 98%)]  Loss: 0.213100: 100%|██████████| 600/600 [00:09<00:00, 64.10it/s]\n",
      "Train Epoch: 90 [59000/60000 ( 98%)]  Loss: 0.370675: 100%|██████████| 600/600 [00:09<00:00, 64.25it/s]\n",
      "Train Epoch: 91 [59000/60000 ( 98%)]  Loss: 0.422782: 100%|██████████| 600/600 [00:09<00:00, 64.78it/s]\n",
      "Train Epoch: 92 [59000/60000 ( 98%)]  Loss: 0.205386: 100%|██████████| 600/600 [00:09<00:00, 65.37it/s]\n",
      "Train Epoch: 93 [59000/60000 ( 98%)]  Loss: 0.207665: 100%|██████████| 600/600 [00:08<00:00, 68.25it/s]\n",
      "Train Epoch: 94 [59000/60000 ( 98%)]  Loss: 0.405699: 100%|██████████| 600/600 [00:08<00:00, 67.42it/s]\n",
      "Train Epoch: 95 [59000/60000 ( 98%)]  Loss: 0.153877: 100%|██████████| 600/600 [00:09<00:00, 64.11it/s]\n",
      "Train Epoch: 96 [59000/60000 ( 98%)]  Loss: 0.380501: 100%|██████████| 600/600 [00:09<00:00, 63.36it/s]\n",
      "Train Epoch: 97 [59000/60000 ( 98%)]  Loss: 0.274802: 100%|██████████| 600/600 [00:09<00:00, 64.73it/s]\n",
      "Train Epoch: 98 [59000/60000 ( 98%)]  Loss: 0.280799: 100%|██████████| 600/600 [00:09<00:00, 65.67it/s]\n",
      "Train Epoch: 99 [59000/60000 ( 98%)]  Loss: 0.203871: 100%|██████████| 600/600 [00:09<00:00, 65.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage space needed by mini LeNet : 29.06 kB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mini_model = MiniLeNet(mask=False).to(device)\n",
    "print(\"MiniLeNet's parameter number :\",sum(p.numel() for p in mini_model.parameters()))\n",
    "\n",
    "train(mini_model, epochs=100)\n",
    "torch.save(mini_model, '../saves/LeNet_mini.ptmodel')\n",
    "\n",
    "path = os.path.expanduser('../saves/LeNet_mini.ptmodel')\n",
    "size_kb_mini = os.path.getsize(path) / 1024\n",
    "print(f\"Storage space needed by mini LeNet : {size_kb_mini:.2f} kB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe506a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.1704, Accuracy: 9580/10000 (95.80%)\n",
      "Test set: Average loss: 0.2859, Accuracy: 9180/10000 (91.80%)\n"
     ]
    }
   ],
   "source": [
    "accuracy_init = test(model_init, use_cuda=use_cuda)\n",
    "accuracy_mini = test(mini_model, use_cuda=use_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
